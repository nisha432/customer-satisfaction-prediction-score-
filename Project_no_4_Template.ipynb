{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "GF8Ens_Soomf",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "yiiVWRdJDDil",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha432/customer-satisfaction-prediction-score-/blob/main/Project_no_4_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - E-Commerce Customer Satisfaction Score Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -** Nisha Ahire\n",
        "##### **Team Member 2 -** Prabhakar Harijan\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DeepCSAT project focuses on predicting customer satisfaction (CSAT) scores for e-commerce platforms using deep learning, particularly Artificial Neural Networks (ANN). The approach begins with ensuring data integrity and cleaning by addressing issues such as missing, duplicate, or irrelevant data points. Through a meticulous cleaning process, the data is refined, ensuring it is accurate, consistent, and ready for analysis, which is crucial for building a reliable model. Once the data is cleaned, the next step is feature engineering and selection. Creative and analytical techniques are used to craft and select features that significantly impact CSAT predictions. This process ensures that the most relevant customer behaviors and interactions are captured, while eliminating unnecessary or redundant features to avoid overfitting and improve model efficiency.\n",
        "\n",
        "Following feature selection, data preprocessing and transformation techniques, including normalization, encoding of categorical variables, and timestamp parsing, are applied. These steps prepare the data in a format suitable for deep learning, ensuring the neural network can effectively learn complex relationships within the data. At the heart of the project is the model development and architecture, where a robust Artificial Neural Network (ANN) is designed. The architecture is carefully crafted with appropriate layers, activation functions, and connectivity patterns to capture the nonlinearities of customer satisfaction data, ensuring the model is capable of generalizing well to unseen data and making accurate predictions.\n",
        "\n",
        "The training process is optimized through the use of training efficiency and optimization strategies. Techniques like batch processing, learning rate adjustments, and early stopping are employed to accelerate convergence while preventing overfitting. This ensures the model trains efficiently, minimizing computational time without compromising performance. To assess model accuracy and robustness, evaluation metrics and model validation are conducted using relevant metrics such as mean absolute error (MAE) or root mean square error (RMSE). Cross-validation or split-sample validation is used to confirm that the model generalizes well to new, unseen data.\n",
        "\n",
        "Incorporating innovative techniques in deep learning, the project explores advanced methods and customizations that improve prediction accuracy. This might involve experimenting with different neural network architectures, hyperparameter tuning, or adding advanced features that enhance the model's predictive power. Once developed, the model is deployed locally, demonstrating its practical application in real-world e-commerce environments and showing how it can be integrated into existing systems to drive improvements in customer satisfaction.\n",
        "\n",
        "Finally, documentation, interpretability, and presentation are prioritized. The project provides clear, structured documentation outlining the data evaluation process, model architecture, and results. Emphasis is placed on model interpretability, offering insights into how specific features influence CSAT predictions. This transparency helps businesses make informed, data-driven decisions to enhance customer experiences. The findings are presented professionally, ensuring that the project’s outcomes and value are clearly communicated to stakeholders and decision-makers.\n",
        "\n",
        "In summary, DeepCSAT integrates deep learning with e-commerce insights to predict customer satisfaction scores accurately. By following a comprehensive approach—ranging from data preparation to model development, training, and evaluation—it provides e-commerce businesses with actionable insights that can improve customer satisfaction, refine product offerings, and drive customer retention."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/nisha432/customer-satisfaction-prediction-score-"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the competitive landscape of e-commerce, customer satisfaction (CSAT) plays a pivotal role in driving customer loyalty, retention, and overall business success. However, accurately assessing and predicting CSAT scores remains a significant challenge due to the complex and multifaceted nature of customer interactions and feedback. Traditional methods of evaluating customer satisfaction are often reactive, relying on surveys or direct feedback, which can be limited, delayed, and subjective.\n",
        "\n",
        "To address this challenge, there is a growing need for predictive models that can analyze large volumes of interaction data in real-time to proactively identify factors influencing customer satisfaction. This project aims to develop a robust predictive model using Deep Learning Artificial Neural Networks (ANN) to forecast CSAT scores based on a diverse set of interaction-related features. By leveraging advanced neural network techniques, the model seeks to provide accurate, data-driven insights that can enhance service quality, optimize customer experience, and drive strategic business decisions in the e-commerce domain.\n",
        "\n",
        "The successful implementation of this solution will enable businesses to proactively address customer concerns, optimize service delivery, and improve customer loyalty, thereby fostering sustainable growth in a highly competitive market"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime\n",
        "import missingno as msno\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.patheffects as path_effects\n",
        "from matplotlib.patheffects import PathPatchEffect, SimpleLineShadow, Normal\n",
        "# Machine Learning and Data Preprocessing Libraries\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, roc_curve, auc,\n",
        "    mean_squared_error, mean_absolute_error, r2_score, classification_report\n",
        ")\n",
        "from yellowbrick.classifier import (\n",
        "    ClassificationReport, PrecisionRecallCurve, ClassPredictionError, DiscriminationThreshold\n",
        ")\n",
        "from yellowbrick.style.palettes import PALETTES, SEQUENCES, color_palette\n",
        "import lightgbm\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\n",
        "\n",
        "# Visualization settings\n",
        "sns.set(style=\"whitegrid\")\n",
        "pd.set_option('display.max_columns', None)\n"
      ],
      "metadata": {
        "id": "E6469izvITcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This is a robust setup for data analysis and machine learning in Python, with a comprehensive selection of libraries for data manipulation (pandas, numpy), visualization (seaborn, matplotlib, plotly), and machine learning (scikit-learn, lightgbm, xgboost). I also included essential libraries for handling missing data (missingno) and added enhanced visualizations for classification with yellowbrick"
      ],
      "metadata": {
        "id": "401oiN91OLYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dYgQDweLA3R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/AlmaBetter/datasets/eCommerce_Customer_support_data.csv\")"
      ],
      "metadata": {
        "id": "PKkry_hwIjAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "qae-eZMKImBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rows, columns = df.shape\n",
        "\n",
        "# Print the results\n",
        "print(f'Number of rows: {rows}')\n",
        "print(f'Number of columns: {columns}')"
      ],
      "metadata": {
        "id": "wzrPVrtQInzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "mllJdzA4Iqyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_count = df.duplicated().sum()\n",
        "\n",
        "# Print the result\n",
        "print(f'Total duplicate rows: {duplicate_count}')"
      ],
      "metadata": {
        "id": "BuIc0PjzI2bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "KaJzyeTlJDLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_counts = df.isnull().sum()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(18, 6))\n",
        "sns.barplot(x=null_counts.index, y=null_counts.values, palette='viridis')\n",
        "plt.title('Count of Null Values in Each Column')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Number of Null Values')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QIISCVyrJaaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ecvUNM9MJf0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "bl8vppspJkbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")\n",
        "\n",
        "unique_dataset = pd.DataFrame()\n",
        "unique_dataset['Features'] = df.columns\n",
        "unique=[]\n",
        "for i in df.columns:\n",
        "    unique.append(df[i].nunique())\n",
        "unique_dataset['Uniques'] = unique\n",
        "\n",
        "f, ax = plt.subplots(1,1, figsize=(15,7))\n",
        "\n",
        "splot = sns.barplot(x=unique_dataset['Features'], y=unique_dataset['Uniques'], alpha=0.8,path_effects=[path_effects.SimplePatchShadow(),path_effects.Normal()],color = 'red')\n",
        "for p in splot.patches:\n",
        "    splot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center',\n",
        "                   va = 'center', xytext = (0, 9), textcoords = 'offset points')\n",
        "plt.title('Bar plot for number of unique values in each column',weight='bold', size=15)\n",
        "plt.ylabel('#Unique values', size=12, weight='bold')\n",
        "plt.xlabel('Features', size=12, weight='bold')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uxsFRYqiJIFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values - dropping rows with missing CSAT for this example\n",
        "df = df.dropna(subset=['CSAT Score'])"
      ],
      "metadata": {
        "id": "ep48jUYgJ8Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert datetime columns and create derived features\n",
        "df['order_date_time'] = pd.to_datetime(df['order_date_time'], dayfirst=True)\n",
        "df['Issue_reported at'] = pd.to_datetime(df['Issue_reported at'], dayfirst=True)\n",
        "df['issue_responded'] = pd.to_datetime(df['issue_responded'], dayfirst=True)\n",
        "df['Survey_response_Date'] = pd.to_datetime(df['Survey_response_Date'], dayfirst=True)\n"
      ],
      "metadata": {
        "id": "j5s2aK8ZJ8QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['order_year'] = df['order_date_time'].dt.year\n",
        "df['order_month'] = df['order_date_time'].dt.month\n",
        "df['order_day'] = df['order_date_time'].dt.day\n",
        "df['order_hour'] = df['order_date_time'].dt.hour\n",
        "df['order_day_of_week'] = df['order_date_time'].dt.dayofweek"
      ],
      "metadata": {
        "id": "UdZw23VBJ8Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate response and survey lag times\n",
        "df['Response Lag'] = (df['issue_responded'] - df['Issue_reported at']).dt.total_seconds() / 3600.0\n",
        "df['Survey Lag'] = (df['Survey_response_Date'] - df['Issue_reported at']).dt.total_seconds() / 3600.0\n"
      ],
      "metadata": {
        "id": "NKmcHzsiJ8LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing text values with 'Unknown'\n",
        "df['Customer Remarks'] = df['Customer Remarks'].fillna('Unknown')\n",
        "df['Customer_City'] = df['Customer_City'].fillna('Unknown')"
      ],
      "metadata": {
        "id": "fPcuB6lPJ8Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing numeric values with median\n",
        "df['Item_price'] = df['Item_price'].fillna(df['Item_price'].median())\n",
        "df['connected_handling_time'] = df['connected_handling_time'].fillna(df['connected_handling_time'].median())\n"
      ],
      "metadata": {
        "id": "qX-_G-5hJ8GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing dates with earliest date in each column\n",
        "for date_col in ['order_date_time', 'Issue_reported at', 'issue_responded']:\n",
        "    df[date_col] = df[date_col].fillna(df[date_col].min())"
      ],
      "metadata": {
        "id": "mVbBX_e6J8EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate response_time and days_since_order\n",
        "df['response_time'] = (df['issue_responded'] - df['Issue_reported at']).dt.total_seconds() / 60  # in minutes\n",
        "df['days_since_order'] = (df['Survey_response_Date'] - df['order_date_time']).dt.days"
      ],
      "metadata": {
        "id": "E13t3P7JJ8CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace negative or NaN days_since_order with 0 for consistency\n",
        "df['days_since_order'] = df['days_since_order'].apply(lambda x: max(x, 0) if pd.notnull(x) else 0)\n"
      ],
      "metadata": {
        "id": "XwFZjGS7J8AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "BrQ5Q504J767"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Product_category'].value_counts()"
      ],
      "metadata": {
        "id": "mlGvpUSkKrVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna('Unknown', inplace=True)"
      ],
      "metadata": {
        "id": "EFgl-KGWK5at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_Qa08LpVK_sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWmGoZeGLKEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df, x='CSAT Score', title=\"CSAT Score Distribution\", nbins=5)\n",
        "fig.update_layout(xaxis_title=\"CSAT Score\", yaxis_title=\"Count\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "TXGOANlVLTYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram is well-suited for visualizing the distribution of a single variable, particularly when the goal is to observe how frequently each customer satisfaction score (CSAT Score) occurs. In this case, CSAT Score has a limited range (1 to 5), making a histogram with 5 bins ideal. It shows the frequency of each score, allowing us to quickly see if customer satisfaction skews toward high or low scores or is more evenly distributed."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " According to histogram we can observe High customer satisfaction."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights could lead to a positive business impact:\n",
        "\n",
        "Customer Feedback Analysis: By identifying satisfaction levels, you can prioritize areas for improvement. For instance, addressing the root causes behind low scores can directly enhance customer experience.\n",
        "\n",
        "Marketing and Retention Efforts: High satisfaction scores provide validation for effective customer service strategies. They can be leveraged in customer testimonials or marketing content to attract new customers and retain existing ones.\n",
        "\n",
        "Operational Adjustments: Consistently low scores may suggest underlying issues in operations or customer interactions that, once corrected, could reduce churn and improve brand loyalty.\n",
        "\n",
        "Analyzing CSAT scores helps focus on enhancing customer satisfaction, ultimately supporting growth through improved service and reputation.Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(df, x='Agent Shift', y='response_time', title=\"Response Time Distribution by Agent Shift\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "43WUFyeALbfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.violinplot(x='Agent Shift', y='response_time', data=df)\n",
        "plt.title(\"Response Time Distribution by Agent Shift\")\n",
        "plt.xlabel(\"Agent Shift\")\n",
        "plt.ylabel(\"Response Time (hours)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VBWEucjKLeEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A box plot is an excellent choice for comparing distributions of response times across different agent shifts because it shows key statistics—like the median, quartiles, and potential outliers—in each shift category. This visualization allows for easy comparison of typical response times and variations between shifts, revealing if certain shifts are associated with longer or shorter response times."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box plot can reveal several valuable insights:\n",
        "\n",
        "Median Response Times: By comparing the median (the line in the box) across shifts, we can identify which shifts tend to have quicker or slower response times.\n",
        "\n",
        "Variability in Response Times: The length of the box (interquartile range) and presence of whiskers or outliers will indicate the consistency of response times within each shift. Shifts with a narrower range are more consistent, while a wider range suggests variability."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can positively impact the business:\n",
        "\n",
        "Shift Scheduling Optimization: Understanding which shifts have longer response times can help identify times of high demand or potential staffing issues. This insight can guide better scheduling or resource allocation to improve response times.\n",
        "\n",
        "Training and Process Improvement: If certain shifts consistently perform better, analyzing their practices could uncover methods or behaviors that can be standardized across all shifts.\n",
        "\n",
        "Enhanced Customer Satisfaction: Reducing response times, especially during shifts with slower responses, can improve overall customer satisfaction, as faster response times are generally associated with better customer service."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(df, x='category', y='CSAT Score', title=\"Category vs. CSAT Score\", color='Agent Shift')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "xM0LaapvLhNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A box plot is an effective choice for comparing customer satisfaction scores (CSAT) across different categories while also distinguishing between different agent shifts. This allows for clear visualization of the distribution of CSAT scores within each category, helping to highlight differences in customer satisfaction levels based on both the product category and the agent shift. Using color to represent agent shifts adds another layer of insight, enabling you to see how the shifts impact satisfaction within each category."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box plot can provide several insights:\n",
        "\n",
        "Distribution of CSAT Scores: The median CSAT scores (the line inside the box) for each category can indicate which categories are perceived more positively by customers.\n",
        "\n",
        "Variability Across Categories: The interquartile range (IQR) of each box reveals how varied the CSAT scores are within that category. A wide box indicates more variability in satisfaction, while a narrow box suggests consistent ratings.\n",
        "\n",
        "Comparative Performance by Agent Shift: By observing how the boxes for different agent shifts overlap within categories, you can assess whether certain shifts perform better or worse in specific categories, highlighting potential issues or strengths.\n",
        "\n",
        "Outliers: The presence of outliers in the box plot can indicate exceptional experiences (either positive or negative) and may warrant further investigation."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained from this visualization can lead to positive business outcomes:\n",
        "\n",
        "Targeted Improvement Strategies: Understanding which categories have lower CSAT scores can help focus improvement efforts. If certain categories consistently receive lower satisfaction ratings, you may need to investigate product quality, service delivery, or customer support specific to those categories.\n",
        "\n",
        "Agent Training and Resources: If one agent shift consistently scores higher in certain categories, their methods and practices can be analyzed and potentially adopted across other shifts to enhance overall customer satisfaction.\n",
        "\n",
        "Product Development and Marketing: Categories that receive high satisfaction scores can be highlighted in marketing campaigns, while those with lower scores might need to be improved before being promoted heavily."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter_3d(df, x='Item_price', y='CSAT Score', z='response_time',\n",
        "                    title=\"CSAT Score vs Item Price vs Response Time\",\n",
        "                    color='Agent Shift',\n",
        "                    labels={'Item_price': 'Item Price', 'CSAT Score': 'CSAT Score', 'response_time': 'Response Time (hours)'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "jDaIYixALmrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 3D scatter plot is an excellent choice for visualizing the relationship among three continuous variables—in this case, Item Price, CSAT Score, and Response Time. It allows for a comprehensive view of how these variables interact with each other simultaneously. The use of color to represent different agent shifts adds another dimension to the analysis, helping identify trends or patterns associated with specific shifts."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 3D scatter plot can yield several insights:\n",
        "\n",
        "Relationships Among Variables: You can observe how Item Price correlates with both CSAT Score and Response Time. For example, do higher-priced items tend to receive higher or lower satisfaction scores? Does response time vary significantly for different price ranges?\n",
        "\n",
        "Patterns by Agent Shift: Different colors corresponding to agent shifts can help identify whether certain shifts perform better or worse concerning the three variables. For instance, one shift might show a cluster of high CSAT scores and low response times for high-priced items, indicating effective handling.\n",
        "\n",
        "Clusters and Trends: Look for any clusters of points, which might suggest groups of items or customer interactions with similar characteristics. Identifying trends within those clusters can guide pricing strategies or operational improvements."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained from this 3D scatter plot can drive positive business outcomes:\n",
        "\n",
        "Pricing Strategies: Understanding how Item Price affects customer satisfaction can inform pricing strategies. If higher-priced items consistently receive lower CSAT scores, this could indicate a need for better value communication or product quality improvement.\n",
        "\n",
        "Resource Allocation: If certain agent shifts consistently show longer response times for specific price ranges, this could signal a need for additional training or resources to improve service delivery.\n",
        "\n",
        "Customer Experience Optimization: Identifying patterns in customer satisfaction related to both price and response time can help optimize the overall customer experience. Adjustments can be made based on data-driven insights, leading to higher satisfaction and potentially increased sales."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_means = df.groupby('category')['CSAT Score'].mean().reset_index()\n",
        "fig = px.bar(category_means, x='category', y='CSAT Score', title=\"Average CSAT Score by Category\",\n",
        "             labels={'category': 'Category', 'CSAT Score': 'Average CSAT Score'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aVyokxfGLpHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is a suitable choice for displaying the average customer satisfaction score (CSAT Score) across different categories. It clearly illustrates the differences in average satisfaction levels, making it easy to compare how each category performs relative to others. The vertical arrangement allows for quick visual assessment of which categories are doing well and which may require attention."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar chart can provide several insights:\n",
        "\n",
        "Comparison of Average Scores: By looking at the heights of the bars, you can quickly identify which categories have higher or lower average CSAT scores. This can help pinpoint areas of strength and those needing improvement.\n",
        "\n",
        "Category Performance Trends: If specific categories consistently rank higher or lower, it may indicate underlying factors that affect customer satisfaction, such as product quality, pricing, or service.\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights derived from this bar chart can lead to several positive business outcomes:\n",
        "\n",
        "Targeted Improvement Initiatives: Categories with lower average CSAT scores can be the focus of targeted improvement initiatives, such as enhancing product quality, customer service training, or refining marketing strategies to better align with customer expectations.\n",
        "\n",
        "Resource Allocation: Understanding which categories are performing well can guide resource allocation for marketing or inventory management, focusing efforts on categories that yield higher satisfaction and, potentially, sales.\n",
        "\n",
        "Marketing and Communication: Highlighting higher-performing categories in marketing materials can help attract customers and improve brand perception. Conversely, addressing lower-performing categories may improve overall customer experience and loyalty."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure and axis\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a box plot using Seaborn\n",
        "box_plot = sns.boxplot(data=df, x='Agent Shift', y='CSAT Score', palette='Set2')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('CSAT Score Distribution by Agent Shift', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Agent Shift', fontsize=14)\n",
        "plt.ylabel('CSAT Score', fontsize=14)\n",
        "\n",
        "# Add grid lines for better readability\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_htjDmUILs7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " the box plot was chosen for its ability to effectively communicate the distribution of CSAT scores across agent shifts, highlight key statistics, and facilitate quick comparisons, making it a valuable tool for analyzing customer satisfaction data."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of CSAT Scores:\n",
        "\n",
        "Each box represents the interquartile range (IQR), showing where the middle 50% of scores lie. The line inside each box indicates the median CSAT score for that shift.\n",
        "Comparative Analysis:\n",
        "\n",
        "You can easily compare the median CSAT scores across different shifts. This helps identify which shifts are performing well and which may have issues.\n",
        "Variability and Outliers:\n",
        "\n",
        "The whiskers of the box plot extend to the minimum and maximum scores within 1.5 times the IQR from the quartiles, while points outside this range are considered outliers. Observing outliers can indicate exceptional cases that may need further investigation.\n",
        "Performance Patterns:\n",
        "\n",
        "If one shift consistently shows higher median CSAT scores and fewer outliers, it may suggest better performance in customer service or operations during that time."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Operational Insights:\n",
        "\n",
        "Understanding which agent shifts perform better in terms of customer satisfaction can help optimize staffing and training. Higher-performing shifts may have practices that could be shared or implemented across other shifts.\n",
        "Resource Allocation:\n",
        "\n",
        "If certain shifts are underperforming, management can allocate more resources, such as training or support, to improve performance during those times.\n",
        "Enhanced Customer Experience:\n",
        "\n",
        "Ultimately, focusing on shifts with lower CSAT scores and implementing changes can lead to improved customer satisfaction, loyalty, and retention"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.regplot(data=df, x='connected_handling_time', y='CSAT Score', scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
        "plt.title('CSAT Score vs. Connected Handling Time')\n",
        "plt.xlabel('Connected Handling Time')\n",
        "plt.ylabel('CSAT Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2CqoPM-LvvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A regression plot is particularly effective for illustrating the relationship between two continuous variables. It not only shows the data points but also includes a fitted line that represents the trend, making it easier to identify correlations."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Assessment:\n",
        " the regression line has a positive slope, it suggests that longer connected handling times may be associated with higher CSAT scores, while a negative slope indicates the opposite.\n",
        "Variability in Scores:\n",
        "\n",
        "The spread of the scatter points around the regression line can indicate how much variability there is in CSAT scores at different levels of connected handling time. A tight cluster around the line suggests a strong correlation, whereas a wider spread indicates more variability in satisfaction.\n",
        "Identifying Trends:\n",
        "\n",
        "The plot can reveal whether certain ranges of connected handling time consistently yield high or low satisfaction scores, informing operational improvements or customer service strategies."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Operational Improvements: Understanding the relationship between handling time and customer satisfaction can help inform training and resource allocation, ultimately leading to improved customer service efficiency.\n",
        "\n",
        "Customer Satisfaction Strategies: If longer handling times correlate with higher satisfaction, it may indicate that spending more time on customer interactions enhances the experience, suggesting a potential shift in operational strategy.\n",
        "\n",
        "Targeted Training: Identifying handling time thresholds that maximize customer satisfaction can lead to focused training programs aimed at achieving those timeframes."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by category and calculate mean CSAT Score\n",
        "category_csat = df.groupby('category')['CSAT Score'].mean().reset_index()\n",
        "\n",
        "# Data for the 3D bar chart\n",
        "categories = category_csat['category']\n",
        "csat_scores = category_csat['CSAT Score']\n",
        "x = np.arange(len(categories))  # the label locations\n",
        "y = np.zeros_like(x)  # starting y position\n",
        "z = np.zeros_like(x)  # starting z position\n",
        "\n",
        "# Create the 3D bar chart\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Create bars\n",
        "ax.bar3d(x, y, z, dx=0.4, dy=0.4, dz=csat_scores, color='cyan', alpha=0.7, edgecolor='k')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Categories')\n",
        "ax.set_ylabel('Y Axis (Not Used)')\n",
        "ax.set_zlabel('Average CSAT Score')\n",
        "ax.set_title('3D Bar Chart of Average CSAT Scores by Category')\n",
        "\n",
        "# Set x-ticks to be the categories\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(categories, rotation=45, ha='right')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gAVS27WqL0qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 3D bar chart is chosen for visualizing the average Customer Satisfaction Score (CSAT Score) across different categories for several reasons:\n",
        "\n",
        "Visual Depth: The 3D aspect adds a visual depth that can make comparisons among categories more engaging and clearer. It allows viewers to see how different categories stack up against each other in terms of average satisfaction.\n",
        "\n",
        "Emphasis on Magnitude: By using height (z-axis) to represent average CSAT scores, it emphasizes the differences in satisfaction levels more distinctly than a 2D chart might.\n",
        "\n",
        "Categorical Comparison: The chart effectively showcases multiple categories, allowing for easy comparison of their respective average scores, which is helpful for identifying which categories perform well and which do not."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 3D bar chart can yield various insights:\n",
        "\n",
        "Category Performance: By comparing the heights of the bars, you can quickly identify which categories have higher or lower average CSAT scores. This helps pinpoint areas of strength and those that may require attention.\n",
        "\n",
        "Magnitude of Differences: The visual representation allows for a clearer understanding of how much one category's average CSAT score differs from another. Categories with significantly higher or lower scores can indicate varying levels of customer satisfaction.\n",
        "\n",
        "Potential Outliers: If some categories have markedly lower scores, they may indicate specific issues or challenges that need to be addressed."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained from this 3D bar chart can drive positive business outcomes:\n",
        "\n",
        "Targeted Improvement Efforts: Identifying categories with lower average CSAT scores can guide where to focus improvement initiatives, such as enhancing product quality, customer service, or operational efficiencies.\n",
        "\n",
        "Resource Allocation: Understanding which categories perform better can help prioritize marketing and promotional efforts, ensuring that resources are allocated effectively to maximize customer satisfaction and engagement.\n",
        "\n",
        "Customer Experience Enhancement: By focusing on categories with lower satisfaction scores, businesses can implement changes that improve customer experiences, leading to higher retention rates and brand loyalty."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows with negative response_time\n",
        "df_filtered = df[df['response_time'] >= 0]\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(\n",
        "    df_filtered,\n",
        "    x='Item_price',\n",
        "    y='CSAT Score',\n",
        "    size='response_time',\n",
        "    color='Agent Shift',\n",
        "    hover_name='Agent_name',\n",
        "    title=\"CSAT Score vs. Item Price with Response Time as Size\"\n",
        ")\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(xaxis_title=\"Item Price\", yaxis_title=\"CSAT Score\")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "xXAe-Oh7L3Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot is ideal for showing relationships between two continuous variables (item price and CSAT Score) while allowing for an additional variable (response time) to be represented through marker size."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Insights:\n",
        "\n",
        "The plot can help reveal whether there is a correlation between item price and CSAT scores. A positive correlation might suggest that higher prices lead to greater customer satisfaction, or vice versa.\n",
        "Response Time Impact:\n",
        "\n",
        "The size of the markers indicates the response time, allowing for an understanding of how this variable interacts with both price and satisfaction. For instance, if larger markers (indicating longer response times) are associated with lower CSAT scores, it may suggest that longer response times negatively impact satisfaction.\n",
        "Agent Shift Performance:\n",
        "\n",
        "Different colors representing agent shifts can help in identifying which shifts perform better or worse in terms of customer satisfaction and how item pricing influences those scores."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pricing Strategy:\n",
        "\n",
        "Understanding the relationship between item price and customer satisfaction can inform pricing strategies, helping to determine optimal price points that enhance customer satisfaction.\n",
        "Operational Improvements:\n",
        "\n",
        "If longer response times correlate with lower CSAT scores, businesses can focus on improving operational efficiencies or agent training to reduce response times, thereby enhancing customer satisfaction.\n",
        "Targeted Training:\n",
        "\n",
        "Insights about specific agent shifts performing better or worse can lead to tailored training and support efforts to improve overall service quality."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming df is your DataFrame containing the data\n",
        "# First, ensure connected_handling_time is numeric\n",
        "df['connected_handling_time'] = pd.to_numeric(df['connected_handling_time'], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN values in 'connected_handling_time' or 'CSAT Score'\n",
        "df_cleaned = df.dropna(subset=['connected_handling_time', 'CSAT Score'])\n",
        "\n",
        "# Plotting the scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df_cleaned, x='connected_handling_time', y='CSAT Score', alpha=0.6)\n",
        "plt.title('Connected Handling Time vs CSAT Score', fontsize=16)\n",
        "plt.xlabel('Connected Handling Time (hours)', fontsize=14)\n",
        "plt.ylabel('CSAT Score', fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Calculating the correlation coefficient\n",
        "correlation = df_cleaned['connected_handling_time'].corr(df_cleaned['CSAT Score'])\n",
        "print(f'Correlation coefficient between connected handling time and CSAT Score: {correlation:.2f}')\n"
      ],
      "metadata": {
        "id": "Tg79_jVVnQZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a scatter plot to visualize the relationship between connected handling time and CSAT Score because:\n",
        "\n",
        "Visualization of Correlation: Scatter plots are effective for showing the relationship between two continuous variables, allowing us to see how one variable changes with respect to another.\n",
        "\n",
        "Identifying Trends: This type of chart can reveal trends, clusters, or outliers in the data, helping to assess whether there is a positive, negative, or no correlation.\n",
        "\n",
        "Easy Interpretation: It allows for quick visual interpretation of the data points and facilitates understanding of potential relationships without getting lost in complex data."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trend Identification: The scatter plot may reveal a trend indicating that as connected handling time increases or decreases, the CSAT Score may show a corresponding increase or decrease. For example, if longer handling times are associated with higher CSAT Scores, this could indicate that more thorough service leads to greater customer satisfaction.\n",
        "\n",
        "Outliers: The chart may also highlight outliers that deviate significantly from the general trend, prompting further investigation into those specific cases to understand what factors might be at play.\n",
        "\n",
        "Correlation Coefficient: The calculated correlation coefficient will quantify the relationship. For instance, a positive correlation (e.g., 0.7) would suggest that higher connected handling time is associated with higher CSAT Scores, whereas a negative correlation would suggest the opposite."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained from this analysis can significantly impact the business by:\n",
        "\n",
        "Improving Customer Satisfaction: If a positive correlation is found, the company may consider investing in longer connected handling times to ensure more thorough customer service, potentially increasing overall CSAT Scores.\n",
        "\n",
        "Resource Allocation: Understanding this relationship can help management allocate resources effectively, ensuring that agents have sufficient time to handle customer issues, which may enhance the customer experience.\n",
        "\n",
        "Training and Development: If certain handling time thresholds correlate with higher satisfaction, the business can tailor training programs for agents to focus on managing these thresholds, ultimately leading to improved performance and customer satisfaction.\n",
        "\n",
        "Data-Driven Decisions: The analysis supports data-driven decision-making, allowing management to implement strategies based on actual customer feedback and service metrics rather than assumptions."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of how Item Price affects CSAT Scores utilizes various charts to provide a comprehensive understanding of the relationship between these two variables. A scatter plot is chosen to visualize the relationship between Item Price and CSAT Scores, as it effectively displays trends, correlations, and outliers, allowing for a quick assessment of how customer satisfaction varies with price changes. Complementing this visual analysis, correlation analysis quantifies the strength and direction of the relationship, providing a numerical value that indicates whether a strong relationship exists. Additionally, a box plot is employed to summarize the distribution of CSAT Scores across different price categories, enabling a comparison of medians and variability within these ranges. Together, these charts offer both visual exploration and quantitative assessment, facilitating data-driven decisions regarding how Item Price impacts customer satisfaction."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trends: You might observe trends where higher item prices correspond to higher or lower CSAT Scores, indicating a possible relationship.\n",
        "\n",
        "Variability: The box plot can reveal variability in CSAT Scores across different price categories, helping to identify if certain price ranges lead to higher satisfaction.\n",
        "\n",
        "Outliers: You may identify outliers in certain price categories that could impact overall insights."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from analyzing the relationship between Item Price and CSAT Scores can indeed lead to a positive business impact. For instance, if a strong positive correlation is found, indicating that higher prices are associated with higher CSAT Scores, the business can focus on premium product offerings or enhanced service levels to boost customer satisfaction. This could lead to increased sales, customer loyalty, and overall profitability."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "The line chart was selected because it effectively shows trends over time, which is ideal for understanding how average CSAT scores vary by date. It allows for an intuitive understanding of any upward or downward trends in customer satisfaction over the period."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap_data = df.groupby(['channel_name', 'category'])['CSAT Score'].mean().unstack()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu')\n",
        "plt.title(\"Heatmap of Average CSAT Score by Channel and Category\")\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Channel Name\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_PrRJBKSL7Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmaps are particularly well-suited for visualizing data that can be structured in a matrix form, such as the relationship between two categorical variables (channel and category) with a third quantitative variable (average CSAT Score)."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Analysis:\n",
        "\n",
        "The heatmap can reveal which combinations of channels and categories yield the highest and lowest average CSAT scores, indicating areas of strength and weakness.\n",
        "Identifying Trends:\n",
        "\n",
        "Consistent patterns across categories and channels can indicate operational efficiencies or issues. For instance, if a particular category consistently has low scores across multiple channels, it may require further investigation.\n",
        "Focus Areas for Improvement:\n",
        "\n",
        "Areas represented by darker colors (indicating lower scores) can guide strategic decisions about where to focus customer service improvements, training, or marketing efforts."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df=df.copy()"
      ],
      "metadata": {
        "id": "AxUme3U0MEU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.isnull().sum()"
      ],
      "metadata": {
        "id": "WlJopuElMHZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df"
      ],
      "metadata": {
        "id": "Go_bCRIHjCbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "BJcKqkrlND_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"Unknown\" with NaN\n",
        "df.replace(\"Unknown\", np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with any NaN values\n",
        "df_cleaned = df.dropna()\n",
        "\n"
      ],
      "metadata": {
        "id": "fJ23HpEdN5Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.info()"
      ],
      "metadata": {
        "id": "JRGG66BMNcrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Create box plots for each numerical column\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    plt.subplot(len(numerical_cols), 1, i)  # create a subplot for each numerical column\n",
        "    sns.boxplot(x=df[col])\n",
        "    plt.title(f'Box Plot of {col}')\n",
        "    plt.xlabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v02iEwmpMfGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df_cleaned"
      ],
      "metadata": {
        "id": "50e30lmBOd3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to handle outliers\n",
        "def handle_outliers(df, column):\n",
        "    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Determine bounds for outliers\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Remove outliers\n",
        "    df_cleaned = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "# Handle outliers for each numerical column in the DataFrame\n",
        "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
        "    df = handle_outliers(df, col)\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "id": "CMqf9M8GOcTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The technique used for outlier treatment is based on the Interquartile Range (IQR) method.This technique IS used because of-\n",
        "\n",
        "Data Integrity: Improves the quality of the dataset by eliminating extreme values.\n",
        "\n",
        "Robustness: Methods like IQR are resilient to extreme observations.\n",
        "\n",
        "Model Performance: Proper outlier handling can enhance the accuracy of predictive models."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "Tuz1oCxIOhuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder to the 'Tenure Bucket' column\n",
        "le.fit(df['Tenure Bucket'])\n",
        "\n",
        "# Create mapping dictionary for 'Tenure Bucket'\n",
        "tenure_mapping = {value: index for index, value in enumerate(le.classes_)}\n",
        "\n",
        "# Print the mapping\n",
        "print(\"Mapping for 'Tenure Bucket':\", tenure_mapping)\n",
        "\n",
        "# Apply mapping to the DataFrame (encoding)\n",
        "df['Tenure Bucket (encoded)'] = df['Tenure Bucket'].map(tenure_mapping)"
      ],
      "metadata": {
        "id": "W6ICsgMmOs-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Initializing the LabelEncoder and fitting it to the 'Tenure Bucket' column.\n",
        "2. Creating a mapping dictionary using le.classes_.\n",
        "3. Applying the mapping to create an encoded column."
      ],
      "metadata": {
        "id": "PrB80cAg83vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the LabelEncoder to the 'Agent Shift' column\n",
        "le.fit(df['Agent Shift'])\n",
        "\n",
        "# Create mapping dictionary for 'Agent Shift'\n",
        "tenure_mapping = {value: index for index, value in enumerate(le.classes_)}\n",
        "\n",
        "# Print the mapping\n",
        "print(\"Mapping for 'Agent Shift':\", tenure_mapping)\n",
        "\n",
        "# Apply mapping to the DataFrame (encoding)\n",
        "df['Agent Shift(encoded)'] = df['Agent Shift'].map(tenure_mapping)"
      ],
      "metadata": {
        "id": "jj7rH4kbVFW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Tenure Bucket','Agent Shift'], inplace=True)"
      ],
      "metadata": {
        "id": "UoGfpS2nOvS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "eWXbHQpbOwL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for numerical and categorical columns\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(\"Numerical Columns:\", numerical_cols)\n",
        "print(\"Categorical Columns:\", categorical_cols)"
      ],
      "metadata": {
        "id": "j99qxLhrPK-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display unique values count for numerical columns\n",
        "print(\"Unique values count in numerical columns:\")\n",
        "for col in numerical_cols:\n",
        "    print(f\"{col}: {df[col].nunique()}\")\n",
        "\n",
        "# Display unique values count for categorical columns\n",
        "print(\"\\nUnique values count in categorical columns:\")\n",
        "for col in categorical_cols:\n",
        "    print(f\"{col}: {df[col].nunique()}\")"
      ],
      "metadata": {
        "id": "dnWHj1SbPRDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_category=pd.get_dummies(df['category'] )\n",
        "df_sub_category=pd.get_dummies(df['Sub-category'],prefix='Sub_category')\n",
        "df_Product_category=pd.get_dummies(df['Product_category'],prefix='Product_category')"
      ],
      "metadata": {
        "id": "AnbiF91bQuVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "1. pd.get_dummies(df['category']):\n",
        "\n",
        "Converts the 'category' column into multiple binary columns (one for each unique category value).\n",
        "Each column will have a value of 1 if that row belongs to that category, otherwise 0.\n",
        "\n",
        "2. pd.get_dummies(df['Sub-category'], prefix='Sub_category'):\n",
        "\n",
        "Converts the 'Sub-category' column similarly, but also adds a prefix to each column name (Sub_category_).\n",
        "\n",
        "3. pd.get_dummies(df['Product_category'], prefix='Product_category'):\n",
        "\n",
        "Converts the 'Product_category' column into binary columns with a prefix (Product_category_)."
      ],
      "metadata": {
        "id": "yoUkTXvhFChx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.join(df_category)\n"
      ],
      "metadata": {
        "id": "jUhSHmJaRRv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".join(): Adds the columns from df_category to df based on the index. If df_category has the same number of rows and the index aligns correctly with df, this will work fine.\n",
        "\n",
        "However, .join() is slightly less efficient than pd.concat() for combining DataFrames, especially if you plan to join multiple DataFrames sequentially."
      ],
      "metadata": {
        "id": "qyR7ff5GQxA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.join(df_sub_category)"
      ],
      "metadata": {
        "id": "fYwp9hRZSZab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.join(df_Product_category)"
      ],
      "metadata": {
        "id": "NNlj0QOtYZFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Yaz4cyB4Sgk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bool_cols = df.select_dtypes(include='bool').columns\n",
        "df[bool_cols] = df[bool_cols].astype(int)"
      ],
      "metadata": {
        "id": "O95sfVIiUqaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "used to convert boolean columns in a pandas DataFrame to integer type."
      ],
      "metadata": {
        "id": "765qaMcTjEok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "7pZRQmDYWKfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the issue resolved time\n",
        "df['issue_resolved_time'] = (df['issue_responded'] - df['Issue_reported at']).dt.total_seconds() / 60  # Convert to minutes\n"
      ],
      "metadata": {
        "id": "d9hU3GnUXRWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "sw9QCW-tX_rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Sub-category','category','Unique id','Customer Remarks','Agent_name','Supervisor','Manager','order_date_time','Customer_City','channel_name'], inplace=True)"
      ],
      "metadata": {
        "id": "RBz-x6mlaRgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['issue_responded','Issue_reported at','Product_category','Order_id','Survey_response_Date','order_year'], inplace=True)"
      ],
      "metadata": {
        "id": "8mdR3IJYaXo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Calculate correlation\n",
        "df.corr"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "yCdMJBNUngnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['connected_handling_time'],inplace=True)"
      ],
      "metadata": {
        "id": "zleoKJ2Gb2xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "npqOHrvccoru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "for col in df:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.displot(x=df[col] , color ='green')\n",
        "  plt.xlabel(col)\n",
        "  plt.axvline(df[col].mean(),color='magenta', linestyle='dashed',linewidth=2)\n",
        "  plt.axvline(df[col].median(),color='cyan', linestyle='dashed',linewidth=2)\n",
        "  plt.show()\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tVRcibWIn2J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(df)\n",
        "print(scaled)\n"
      ],
      "metadata": {
        "id": "t9enpMyegyqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separating the dependent and independent variables\n",
        "y = df['CSAT Score']\n",
        "x = df.drop(columns = 'CSAT Score')\n",
        "\n",
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x_train, x_test, y_train, y_test = train_test_split( x,y , test_size = 0.2, random_state = 0)\n"
      ],
      "metadata": {
        "id": "Y9-FwavvhM0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this parameter indicates that 20% of the data will be used for testing, while 80% will be used for training."
      ],
      "metadata": {
        "id": "paeE27jyoZrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['CSAT Score'].value_counts()"
      ],
      "metadata": {
        "id": "uAJMesmahYM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "x_res, y_res = sm.fit_resample(x_train, y_train)"
      ],
      "metadata": {
        "id": "B83hPyknrc1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " SMOTE (Synthetic Minority Over-sampling Technique) from the imblearn (imbalanced-learn) library to address class imbalance in the dataset by oversampling the minority class in the target variable"
      ],
      "metadata": {
        "id": "cw7eFOJIrWNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('After OverSampling, the shape of train_X: {}'.format(x_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1.0)))\n",
        "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_res == 2.0)))\n",
        "print(\"After OverSampling, counts of label '3': {}\".format(sum(y_res == 3.0)))\n",
        "print(\"After OverSampling, counts of label '4': {}\".format(sum(y_res == 4.0)))\n",
        "print(\"After OverSampling, counts of label '5': {}\".format(sum(y_res == 5.0)))\n"
      ],
      "metadata": {
        "id": "krwwiCTDjdcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying SMOTE to the dataset, the class distribution is balanced"
      ],
      "metadata": {
        "id": "O2MeOBQ9sRgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ANN Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "k3SyyUMJlIE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "NLdMZsxmk2X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "kAPnn21RlFP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_res, tf.keras.utils.to_categorical(y_res - 1), epochs=1000, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "ephgNHYMltrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " it trains a machine learning model using TensorFlow and Keras, specifically applying the fit method to train the model with the resampled data after SMOTE."
      ],
      "metadata": {
        "id": "h-A4bImDuSbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model for future use\n",
        "model.save('csat_prediction_model.keras')"
      ],
      "metadata": {
        "id": "AtNwrxs7oyL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model when needed for predictions\n",
        "from tensorflow.keras.models import load_model\n",
        "# Load the trained model\n",
        "loaded_model = load_model('/content/csat_prediction_model.keras')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fFp48C8alvH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def preprocess_input(data):\n",
        "    \"\"\"\n",
        "    This function accepts a raw data dictionary, preprocesses it to match the training format,\n",
        "    and returns the processed input for the model.\n",
        "    \"\"\"\n",
        "    # Convert to DataFrame\n",
        "    input_df = pd.DataFrame([data])\n",
        "\n",
        "    # Handle missing values\n",
        "    input_df['Customer Remarks'] = input_df['Customer Remarks'].fillna('Unknown')\n",
        "    input_df['Customer_City'] = input_df['Customer_City'].fillna('Unknown')\n",
        "    input_df['Item_price'] = input_df['Item_price'].fillna(input_df['Item_price'].median())\n",
        "    # Change to 0 if connect handling time is empty\n",
        "    input_df['connected_handling_time'] = input_df['connected_handling_time'].replace('', '0').astype(float)\n",
        "    input_df['connected_handling_time'] = input_df['connected_handling_time'].fillna(input_df['connected_handling_time'].median())\n",
        "\n",
        "    # Convert datetime columns\n",
        "    datetime_cols = ['order_date_time', 'Issue_reported at', 'issue_responded', 'Survey_response_Date']\n",
        "    for col in datetime_cols:\n",
        "        input_df[col] = pd.to_datetime(input_df[col], errors='coerce', dayfirst=True)\n",
        "\n",
        "    # Create additional features\n",
        "    input_df['order_year'] = input_df['order_date_time'].dt.year\n",
        "    input_df['order_month'] = input_df['order_date_time'].dt.month\n",
        "    input_df['order_day'] = input_df['order_date_time'].dt.day\n",
        "    input_df['order_hour'] = input_df['order_date_time'].dt.hour\n",
        "    input_df['order_day_of_week'] = input_df['order_date_time'].dt.dayofweek\n",
        "\n",
        "    input_df['Response Lag'] = (input_df['issue_responded'] - input_df['Issue_reported at']).dt.total_seconds() / 3600.0\n",
        "    input_df['Survey Lag'] = (input_df['Survey_response_Date'] - input_df['Issue_reported at']).dt.total_seconds() / 3600.0\n",
        "\n",
        "    # Label encode columns as in training\n",
        "    le = LabelEncoder()\n",
        "    input_df['Tenure Bucket (encoded)'] = le.fit_transform(input_df['Tenure Bucket'])\n",
        "    input_df['Agent Shift(encoded)'] = le.fit_transform(input_df['Agent Shift'])\n",
        "\n",
        "    # Drop original columns that were encoded\n",
        "    input_df.drop(columns=['Tenure Bucket', 'Agent Shift'], inplace=True)\n",
        "\n",
        "    # One-hot encode categorical columns\n",
        "    df_category = pd.get_dummies(input_df['category'])\n",
        "    df_sub_category = pd.get_dummies(input_df['Sub-category'], prefix='Sub_category')\n",
        "    df_Product_category = pd.get_dummies(input_df['Product_category'], prefix='Product_category')\n",
        "    input_df = pd.concat([input_df, df_category, df_sub_category, df_Product_category], axis=1)\n",
        "\n",
        "    # Transform boolean columns to int (if any)\n",
        "    bool_cols = input_df.select_dtypes(include='bool').columns\n",
        "    input_df[bool_cols] = input_df[bool_cols].astype(int)\n",
        "\n",
        "    # Drop unnecessary columns as done in training\n",
        "    drop_cols = ['Sub-category', 'category', 'Unique id', 'Customer Remarks', 'Agent_name',\n",
        "                 'Supervisor', 'Manager', 'order_date_time', 'Customer_City', 'channel_name',\n",
        "                 'issue_responded', 'Issue_reported at', 'Product_category', 'Order_id',\n",
        "                 'Survey_response_Date', 'order_year']\n",
        "\n",
        "    input_df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
        "\n",
        "    # Ensure the input data matches the training set columns\n",
        "    input_df = input_df.reindex(columns=x_train.columns, fill_value=0)\n",
        "\n",
        "    return input_df"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "mgOI6RZfX8qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_csat(input_data):\n",
        "    \"\"\"\n",
        "    Accepts preprocessed input data, uses the loaded model to predict the CSAT score, and returns the result.\n",
        "    \"\"\"\n",
        "    processed_data = preprocess_input(input_data)\n",
        "    prediction = loaded_model.predict(processed_data)\n",
        "    predicted_class = np.argmax(prediction, axis=1) + 1  # Add 1 to match the CSAT score (1 to 5)\n",
        "    return predicted_class[0]\n"
      ],
      "metadata": {
        "id": "xUeTdVrMrFyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\n",
        "    'Unique id': '081f62d7-332f-4aac-91cf-e79758976725',\n",
        "    'channel_name': 'Inbound',\n",
        "    'category': 'Returns',\n",
        "    'Sub-category': 'Reverse Pickup Enquiry',\n",
        "    'Customer Remarks': '',  # Can be left empty\n",
        "    'Order_id': '2509fa08-318d-4526-8122-51603af956a8',\n",
        "    'order_date_time': '15-07-2023 14:47',  # Changeable\n",
        "    'Issue_reported at': '01-08-2023 08:55',  # Changeable\n",
        "    'issue_responded': '01-08-2023 08:57',  # Changeable\n",
        "    'Survey_response_Date': '01-Aug-23',  # Changeable\n",
        "    'Customer_City': 'BETIA',\n",
        "    'Product_category': 'Electronics',\n",
        "    'Item_price': 1099,  # Changeable\n",
        "    'connected_handling_time': '',  # Can be left empty\n",
        "    'Agent_name': 'Cynthia Mills',\n",
        "    'Supervisor': 'William Park',\n",
        "    'Manager': 'John Smith',\n",
        "    'Tenure Bucket': '31-60',\n",
        "    'Agent Shift': 'Morning'\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wJ_TE7Zqxcqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run prediction\n",
        "predicted_score = predict_csat(input_data)\n"
      ],
      "metadata": {
        "id": "1V4ob4kPk0wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Predicted CSAT Score: {predicted_score}')"
      ],
      "metadata": {
        "id": "XeLQ3KqT5lpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**"
      ],
      "metadata": {
        "id": "P9h3gtCQw-ND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project successfully developed a deep learning model to predict Customer Satisfaction (CSAT) scores for an e-commerce platform. The project involved a series of key steps that were carefully designed to handle the complexities of the dataset and ensure reliable predictions. First, we preprocessed the raw data by addressing missing values, encoding categorical variables, and creating meaningful features such as Response Lag and Survey Lag, which are critical in determining customer satisfaction. We also tackled the issue of class imbalance by applying SMOTE to resample the data, ensuring that the model learned to predict across all satisfaction levels equally.\n",
        "\n",
        "Next, we built a robust Deep Neural Network (DNN) model capable of capturing complex relationships within the data. The model was trained using efficient techniques such as batch processing, learning rate optimization, and early stopping to prevent overfitting. After training, we evaluated the model using relevant performance metrics, and the results showed that it was capable of predicting CSAT scores with a reasonable degree of accuracy.\n",
        "\n",
        "A key part of this project was the development of a preprocessing pipeline that allows the model to handle new input data consistently, ensuring that predictions can be made in real-time on fresh customer interactions. The pipeline transforms raw data into a format compatible with the trained model, enabling businesses to take immediate action based on predicted satisfaction scores. Additionally, the insights derived from the model can help organizations identify areas for improvement in customer service, ultimately enhancing customer experience.\n",
        "\n",
        "While the model shows promising results, there are opportunities for further improvement. For example, incorporating additional features, such as sentiment analysis of customer feedback or refining the model’s architecture, could enhance its predictive power. Furthermore, real-time deployment could allow the model to provide on-the-fly insights, enabling proactive measures to improve customer satisfaction. Overall, this project demonstrates the potential of deep learning in predictive analytics and highlights the importance of effective data preprocessing, feature engineering, and model optimization in building accurate and actionable customer satisfaction models."
      ],
      "metadata": {
        "id": "Je609kN8wk5u"
      }
    }
  ]
}